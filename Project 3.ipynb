{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, Bidirectional\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "import keras.callbacks\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from utils import clean_tweet, tokenize_tweet\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importer le word2vec google\n",
    "WORD2VEC_VECTORS_BIN = 'C:\\\\Users\\\\PC\\\\python\\\\deep learning\\\\Projet\\\\GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_VECTORS_BIN, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "##lecture des donnes\n",
    "data_clickbait=pd.read_csv('clickbait_data',sep='\\n',header=None)\n",
    "data_noclickbait=pd.read_csv('non_clickbait_data',sep='\\n',header=None)\n",
    "\n",
    "data_clickbait.insert(1,\"class\",np.ones(15999))\n",
    "data_noclickbait.insert(1,\"class\",np.zeros(16001))\n",
    "\n",
    "data_Final=pd.concat((data_clickbait,data_noclickbait),ignore_index=True) # concatenation des click vs nonclick data\n",
    "df=data_Final.rename(columns={0:\"text\"}) # renommer la colonne 0\n",
    "df=df.sample(frac=1).reset_index(drop=True) # faire un shuffle avec reset index ( index remit a zero)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data cleaning\n",
    "df['cleaned_tweet'] = df['text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##separer les donnes de façon non aléatoire pour eviter d'avoir un probleme lors de la cross validation a cause des indexs\n",
    "\n",
    "split=int(2*len(df)/3)\n",
    "\n",
    "text_train,text_test,y_train,y_test=df.iloc[:split,2],df.iloc[split:,2],df.iloc[:split,1],df.iloc[split:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## appliquer le word2vec de google mais Charactere par Charactere !!\n",
    "\n",
    "dimsize=300\n",
    "sequence_size=30\n",
    "\n",
    "def compute_matrix(Text):\n",
    "    X = np.zeros((len(Text), sequence_size, dimsize))\n",
    "    for idx, review in enumerate(Text):\n",
    "        sequence = np.zeros((sequence_size, dimsize))\n",
    "        tokens = review\n",
    "        count = 0\n",
    "        for token in tokens:\n",
    "            if count == sequence_size:\n",
    "                break\n",
    "            try:\n",
    "                token = token.lower()\n",
    "                sequence[count] = w2v[token]\n",
    "                count += 1\n",
    "            except:\n",
    "                pass\n",
    "        X[idx] = sequence\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=compute_matrix(text_train)\n",
    "X_test=compute_matrix(text_test)\n",
    "\n",
    "##creer le model \n",
    "def creat_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(GRU(64, dropout=0.3), input_shape=(sequence_size, dimsize)))  # try using a GRU instead, for fun\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='ADAM',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "def fit_model(model,X_train,y_train,x_valid,y_valid,batch_size = 64):\n",
    "\n",
    "    #earlystop_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=20,validation_data=[x_valid,y_valid],callbacks=callback_list)\n",
    "    #score, acc = model.evaluate(X_test, y_test,batch_size=batch_size)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## definir un fichier qui sauvegarde les poids du meilleur modele\n",
    "cp=ModelCheckpoint(\"best_model.h5\",verbose=1,save_best_only=True) \n",
    "callback_list=[cp] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19199, 30, 300) (19199,) (2134, 30, 300) (2134,)\n",
      "Running Fold 1 / 10\n",
      "Train on 19199 samples, validate on 2134 samples\n",
      "Epoch 1/20\n",
      "19199/19199 [==============================] - 37s 2ms/step - loss: 0.4216 - accuracy: 0.8141 - val_loss: 0.3206 - val_accuracy: 0.8655\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32059, saving model to best_model.h5\n",
      "Epoch 2/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.3162 - accuracy: 0.8715 - val_loss: 0.2917 - val_accuracy: 0.8843\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32059 to 0.29175, saving model to best_model.h5\n",
      "Epoch 3/20\n",
      "19199/19199 [==============================] - 38s 2ms/step - loss: 0.2722 - accuracy: 0.8908 - val_loss: 0.2606 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29175 to 0.26063, saving model to best_model.h5\n",
      "Epoch 4/20\n",
      "19199/19199 [==============================] - 37s 2ms/step - loss: 0.2428 - accuracy: 0.9031 - val_loss: 0.2429 - val_accuracy: 0.9067\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26063 to 0.24285, saving model to best_model.h5\n",
      "Epoch 5/20\n",
      "19199/19199 [==============================] - 36s 2ms/step - loss: 0.2211 - accuracy: 0.9123 - val_loss: 0.2370 - val_accuracy: 0.9105\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.24285 to 0.23699, saving model to best_model.h5\n",
      "Epoch 6/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.2016 - accuracy: 0.9213 - val_loss: 0.2228 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.23699 to 0.22282, saving model to best_model.h5\n",
      "Epoch 7/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.1852 - accuracy: 0.9294 - val_loss: 0.2142 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.22282 to 0.21423, saving model to best_model.h5\n",
      "Epoch 8/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.1706 - accuracy: 0.9343 - val_loss: 0.2075 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.21423 to 0.20754, saving model to best_model.h5\n",
      "Epoch 9/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.1515 - accuracy: 0.9422 - val_loss: 0.2133 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20754\n",
      "Epoch 10/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.1337 - accuracy: 0.9509 - val_loss: 0.2116 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20754\n",
      "Epoch 11/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.1223 - accuracy: 0.9536 - val_loss: 0.2040 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.20754 to 0.20399, saving model to best_model.h5\n",
      "Epoch 12/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.1058 - accuracy: 0.9598 - val_loss: 0.2222 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20399\n",
      "Epoch 13/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.0941 - accuracy: 0.9656 - val_loss: 0.2332 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20399\n",
      "Epoch 14/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.0755 - accuracy: 0.9726 - val_loss: 0.2412 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20399\n",
      "Epoch 15/20\n",
      "19199/19199 [==============================] - 37s 2ms/step - loss: 0.0639 - accuracy: 0.9767 - val_loss: 0.2474 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20399\n",
      "Epoch 16/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.0526 - accuracy: 0.9814 - val_loss: 0.2765 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20399\n",
      "Epoch 17/20\n",
      "19199/19199 [==============================] - 36s 2ms/step - loss: 0.0403 - accuracy: 0.9861 - val_loss: 0.3031 - val_accuracy: 0.9147\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20399\n",
      "Epoch 18/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.0347 - accuracy: 0.9872 - val_loss: 0.3294 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20399\n",
      "Epoch 19/20\n",
      "19199/19199 [==============================] - 37s 2ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.3168 - val_accuracy: 0.9185\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20399\n",
      "Epoch 20/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.3085 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20399\n",
      "(19199, 30, 300) (19199,) (2134, 30, 300) (2134,)\n",
      "Running Fold 2 / 10\n",
      "Train on 19199 samples, validate on 2134 samples\n",
      "Epoch 1/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.4271 - accuracy: 0.8106 - val_loss: 0.3165 - val_accuracy: 0.8777\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.20399\n",
      "Epoch 2/20\n",
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.3185 - accuracy: 0.8700 - val_loss: 0.2838 - val_accuracy: 0.8871\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20399\n",
      "Epoch 3/20\n",
      "19199/19199 [==============================] - 41s 2ms/step - loss: 0.2806 - accuracy: 0.8860 - val_loss: 0.2494 - val_accuracy: 0.8997\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20399\n",
      "Epoch 4/20\n",
      "19199/19199 [==============================] - 36s 2ms/step - loss: 0.2497 - accuracy: 0.8977 - val_loss: 0.2274 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20399\n",
      "Epoch 5/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.2258 - accuracy: 0.9099 - val_loss: 0.2210 - val_accuracy: 0.9105\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20399\n",
      "Epoch 6/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.2071 - accuracy: 0.9180 - val_loss: 0.2035 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20399 to 0.20353, saving model to best_model.h5\n",
      "Epoch 7/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.1884 - accuracy: 0.9259 - val_loss: 0.1949 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20353 to 0.19492, saving model to best_model.h5\n",
      "Epoch 8/20\n",
      "19199/19199 [==============================] - 36s 2ms/step - loss: 0.1693 - accuracy: 0.9332 - val_loss: 0.1992 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19492\n",
      "Epoch 9/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.1551 - accuracy: 0.9402 - val_loss: 0.2034 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19492\n",
      "Epoch 10/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.1387 - accuracy: 0.9458 - val_loss: 0.2050 - val_accuracy: 0.9203\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19492\n",
      "Epoch 11/20\n",
      "19199/19199 [==============================] - 36s 2ms/step - loss: 0.1232 - accuracy: 0.9534 - val_loss: 0.1936 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.19492 to 0.19355, saving model to best_model.h5\n",
      "Epoch 12/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.1050 - accuracy: 0.9607 - val_loss: 0.1982 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.19355\n",
      "Epoch 13/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.0894 - accuracy: 0.9670 - val_loss: 0.2082 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.19355\n",
      "Epoch 14/20\n",
      "19199/19199 [==============================] - 37s 2ms/step - loss: 0.0755 - accuracy: 0.9715 - val_loss: 0.2235 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.19355\n",
      "Epoch 15/20\n",
      "19199/19199 [==============================] - 37s 2ms/step - loss: 0.0643 - accuracy: 0.9754 - val_loss: 0.2297 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19355\n",
      "Epoch 16/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.2437 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19355\n",
      "Epoch 17/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.0389 - accuracy: 0.9873 - val_loss: 0.2654 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.19355\n",
      "Epoch 18/20\n",
      "19199/19199 [==============================] - 35s 2ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.2865 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.19355\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19199/19199 [==============================] - 34s 2ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 0.2839 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.19355\n",
      "Epoch 20/20\n",
      "19199/19199 [==============================] - 36s 2ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.3119 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.19355\n",
      "(19199, 30, 300) (19199,) (2134, 30, 300) (2134,)\n",
      "Running Fold 3 / 10\n",
      "Train on 19199 samples, validate on 2134 samples\n",
      "Epoch 1/20\n",
      "19199/19199 [==============================] - 42s 2ms/step - loss: 0.4131 - accuracy: 0.8169 - val_loss: 0.3224 - val_accuracy: 0.8735\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.19355\n",
      "Epoch 2/20\n",
      "19199/19199 [==============================] - 41s 2ms/step - loss: 0.3138 - accuracy: 0.8738 - val_loss: 0.2884 - val_accuracy: 0.8810\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19355\n",
      "Epoch 3/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.2719 - accuracy: 0.8895 - val_loss: 0.2563 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19355\n",
      "Epoch 4/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.2437 - accuracy: 0.9029 - val_loss: 0.2495 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19355\n",
      "Epoch 5/20\n",
      "19199/19199 [==============================] - 41s 2ms/step - loss: 0.2211 - accuracy: 0.9128 - val_loss: 0.2315 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19355\n",
      "Epoch 6/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.2056 - accuracy: 0.9182 - val_loss: 0.2191 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.19355\n",
      "Epoch 7/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.1891 - accuracy: 0.9281 - val_loss: 0.2178 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19355\n",
      "Epoch 8/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.1712 - accuracy: 0.9354 - val_loss: 0.2178 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19355\n",
      "Epoch 9/20\n",
      "19199/19199 [==============================] - 39s 2ms/step - loss: 0.1563 - accuracy: 0.9394 - val_loss: 0.2049 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19355\n",
      "Epoch 10/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.1412 - accuracy: 0.9467 - val_loss: 0.2073 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19355\n",
      "Epoch 11/20\n",
      "19199/19199 [==============================] - 41s 2ms/step - loss: 0.1255 - accuracy: 0.9528 - val_loss: 0.2056 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.19355\n",
      "Epoch 12/20\n",
      "19199/19199 [==============================] - 39s 2ms/step - loss: 0.1083 - accuracy: 0.9598 - val_loss: 0.1969 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.19355\n",
      "Epoch 13/20\n",
      "19199/19199 [==============================] - 39s 2ms/step - loss: 0.0940 - accuracy: 0.9652 - val_loss: 0.2046 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.19355\n",
      "Epoch 14/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.0800 - accuracy: 0.9699 - val_loss: 0.2064 - val_accuracy: 0.9335\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.19355\n",
      "Epoch 15/20\n",
      "19199/19199 [==============================] - 39s 2ms/step - loss: 0.0655 - accuracy: 0.9759 - val_loss: 0.2321 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19355\n",
      "Epoch 16/20\n",
      "19199/19199 [==============================] - 40s 2ms/step - loss: 0.0574 - accuracy: 0.9797 - val_loss: 0.2229 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19355\n",
      "Epoch 17/20\n",
      "19199/19199 [==============================] - 41s 2ms/step - loss: 0.0422 - accuracy: 0.9847 - val_loss: 0.2373 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.19355\n",
      "Epoch 18/20\n",
      "19199/19199 [==============================] - 39s 2ms/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.2781 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.19355\n",
      "Epoch 19/20\n",
      "19199/19199 [==============================] - 41s 2ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.2927 - val_accuracy: 0.9353\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.19355\n",
      "Epoch 20/20\n",
      "19199/19199 [==============================] - 39s 2ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.2970 - val_accuracy: 0.9391\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.19355\n",
      "(19200, 30, 300) (19200,) (2133, 30, 300) (2133,)\n",
      "Running Fold 4 / 10\n",
      "Train on 19200 samples, validate on 2133 samples\n",
      "Epoch 1/20\n",
      "19200/19200 [==============================] - 45s 2ms/step - loss: 0.4251 - accuracy: 0.8086 - val_loss: 0.3202 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.19355\n",
      "Epoch 2/20\n",
      "19200/19200 [==============================] - 43s 2ms/step - loss: 0.3187 - accuracy: 0.8723 - val_loss: 0.2869 - val_accuracy: 0.8880\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19355\n",
      "Epoch 3/20\n",
      "19200/19200 [==============================] - 44s 2ms/step - loss: 0.2788 - accuracy: 0.8868 - val_loss: 0.2487 - val_accuracy: 0.8997\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19355\n",
      "Epoch 4/20\n",
      "19200/19200 [==============================] - 47s 2ms/step - loss: 0.2469 - accuracy: 0.9013 - val_loss: 0.2222 - val_accuracy: 0.9123\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19355\n",
      "Epoch 5/20\n",
      "19200/19200 [==============================] - 46s 2ms/step - loss: 0.2247 - accuracy: 0.9114 - val_loss: 0.2231 - val_accuracy: 0.9147\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19355\n",
      "Epoch 6/20\n",
      "19200/19200 [==============================] - 46s 2ms/step - loss: 0.2062 - accuracy: 0.9184 - val_loss: 0.2086 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.19355\n",
      "Epoch 7/20\n",
      "19200/19200 [==============================] - 47s 2ms/step - loss: 0.1856 - accuracy: 0.9287 - val_loss: 0.2056 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19355\n",
      "Epoch 8/20\n",
      "19200/19200 [==============================] - 46s 2ms/step - loss: 0.1722 - accuracy: 0.9333 - val_loss: 0.1839 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19355 to 0.18393, saving model to best_model.h5\n",
      "Epoch 9/20\n",
      "19200/19200 [==============================] - 53s 3ms/step - loss: 0.1525 - accuracy: 0.9406 - val_loss: 0.1872 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18393\n",
      "Epoch 10/20\n",
      "19200/19200 [==============================] - 74s 4ms/step - loss: 0.1400 - accuracy: 0.9475 - val_loss: 0.1849 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18393\n",
      "Epoch 11/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.1259 - accuracy: 0.9524 - val_loss: 0.1934 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18393\n",
      "Epoch 12/20\n",
      "19200/19200 [==============================] - 73s 4ms/step - loss: 0.1137 - accuracy: 0.9570 - val_loss: 0.1941 - val_accuracy: 0.9339\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18393\n",
      "Epoch 13/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.0955 - accuracy: 0.9646 - val_loss: 0.1976 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18393\n",
      "Epoch 14/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.0791 - accuracy: 0.9713 - val_loss: 0.2124 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18393\n",
      "Epoch 15/20\n",
      "19200/19200 [==============================] - 73s 4ms/step - loss: 0.0694 - accuracy: 0.9751 - val_loss: 0.2222 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18393\n",
      "Epoch 16/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.0557 - accuracy: 0.9806 - val_loss: 0.2369 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18393\n",
      "Epoch 17/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.0470 - accuracy: 0.9825 - val_loss: 0.2387 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.18393\n",
      "Epoch 18/20\n",
      "19200/19200 [==============================] - 73s 4ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 0.2623 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18393\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.2607 - val_accuracy: 0.9353\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18393\n",
      "Epoch 20/20\n",
      "19200/19200 [==============================] - 70s 4ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.2698 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18393\n",
      "(19200, 30, 300) (19200,) (2133, 30, 300) (2133,)\n",
      "Running Fold 5 / 10\n",
      "Train on 19200 samples, validate on 2133 samples\n",
      "Epoch 1/20\n",
      "19200/19200 [==============================] - 78s 4ms/step - loss: 0.4221 - accuracy: 0.8123 - val_loss: 0.3343 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.18393\n",
      "Epoch 2/20\n",
      "19200/19200 [==============================] - 76s 4ms/step - loss: 0.3121 - accuracy: 0.8743 - val_loss: 0.2996 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18393\n",
      "Epoch 3/20\n",
      "19200/19200 [==============================] - 77s 4ms/step - loss: 0.2708 - accuracy: 0.8921 - val_loss: 0.2775 - val_accuracy: 0.8884\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18393\n",
      "Epoch 4/20\n",
      "19200/19200 [==============================] - 76s 4ms/step - loss: 0.2384 - accuracy: 0.9043 - val_loss: 0.2589 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18393\n",
      "Epoch 5/20\n",
      "19200/19200 [==============================] - 77s 4ms/step - loss: 0.2226 - accuracy: 0.9140 - val_loss: 0.2477 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18393\n",
      "Epoch 6/20\n",
      "19200/19200 [==============================] - 81s 4ms/step - loss: 0.2014 - accuracy: 0.9209 - val_loss: 0.2280 - val_accuracy: 0.9044\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18393\n",
      "Epoch 7/20\n",
      "19200/19200 [==============================] - 80s 4ms/step - loss: 0.1875 - accuracy: 0.9277 - val_loss: 0.2208 - val_accuracy: 0.9123\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18393\n",
      "Epoch 8/20\n",
      "19200/19200 [==============================] - 81s 4ms/step - loss: 0.1676 - accuracy: 0.9358 - val_loss: 0.2161 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18393\n",
      "Epoch 9/20\n",
      "19200/19200 [==============================] - 80s 4ms/step - loss: 0.1544 - accuracy: 0.9406 - val_loss: 0.2080 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18393\n",
      "Epoch 10/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.1367 - accuracy: 0.9481 - val_loss: 0.2049 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18393\n",
      "Epoch 11/20\n",
      "19200/19200 [==============================] - 77s 4ms/step - loss: 0.1220 - accuracy: 0.9540 - val_loss: 0.2233 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18393\n",
      "Epoch 12/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.1115 - accuracy: 0.9580 - val_loss: 0.2150 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18393\n",
      "Epoch 13/20\n",
      "19200/19200 [==============================] - 77s 4ms/step - loss: 0.0934 - accuracy: 0.9655 - val_loss: 0.2213 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18393\n",
      "Epoch 14/20\n",
      "19200/19200 [==============================] - 77s 4ms/step - loss: 0.0788 - accuracy: 0.9711 - val_loss: 0.2503 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18393\n",
      "Epoch 15/20\n",
      "19200/19200 [==============================] - 77s 4ms/step - loss: 0.0684 - accuracy: 0.9750 - val_loss: 0.2442 - val_accuracy: 0.9203\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18393\n",
      "Epoch 16/20\n",
      "19200/19200 [==============================] - 81s 4ms/step - loss: 0.0600 - accuracy: 0.9779 - val_loss: 0.2591 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18393\n",
      "Epoch 17/20\n",
      "19200/19200 [==============================] - 80s 4ms/step - loss: 0.0438 - accuracy: 0.9849 - val_loss: 0.2761 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.18393\n",
      "Epoch 18/20\n",
      "19200/19200 [==============================] - 81s 4ms/step - loss: 0.0343 - accuracy: 0.9874 - val_loss: 0.2771 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18393\n",
      "Epoch 19/20\n",
      "19200/19200 [==============================] - 80s 4ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.2954 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18393\n",
      "Epoch 20/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.3024 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18393\n",
      "(19200, 30, 300) (19200,) (2133, 30, 300) (2133,)\n",
      "Running Fold 6 / 10\n",
      "Train on 19200 samples, validate on 2133 samples\n",
      "Epoch 1/20\n",
      "19200/19200 [==============================] - 82s 4ms/step - loss: 0.4159 - accuracy: 0.8155 - val_loss: 0.3706 - val_accuracy: 0.8523\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.18393\n",
      "Epoch 2/20\n",
      "19200/19200 [==============================] - 82s 4ms/step - loss: 0.3131 - accuracy: 0.8737 - val_loss: 0.3018 - val_accuracy: 0.8790\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18393\n",
      "Epoch 3/20\n",
      "19200/19200 [==============================] - 80s 4ms/step - loss: 0.2752 - accuracy: 0.8891 - val_loss: 0.2810 - val_accuracy: 0.8795\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18393\n",
      "Epoch 4/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.2444 - accuracy: 0.9022 - val_loss: 0.2474 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18393\n",
      "Epoch 5/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.2183 - accuracy: 0.9137 - val_loss: 0.2374 - val_accuracy: 0.9039\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18393\n",
      "Epoch 6/20\n",
      "19200/19200 [==============================] - 80s 4ms/step - loss: 0.2030 - accuracy: 0.9219 - val_loss: 0.2263 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18393\n",
      "Epoch 7/20\n",
      "19200/19200 [==============================] - 80s 4ms/step - loss: 0.1860 - accuracy: 0.9284 - val_loss: 0.2205 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18393\n",
      "Epoch 8/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.1696 - accuracy: 0.9355 - val_loss: 0.2137 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18393\n",
      "Epoch 9/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.1581 - accuracy: 0.9399 - val_loss: 0.2074 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18393\n",
      "Epoch 10/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.1384 - accuracy: 0.9477 - val_loss: 0.2113 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18393\n",
      "Epoch 11/20\n",
      "19200/19200 [==============================] - 82s 4ms/step - loss: 0.1259 - accuracy: 0.9520 - val_loss: 0.2078 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18393\n",
      "Epoch 12/20\n",
      "19200/19200 [==============================] - 78s 4ms/step - loss: 0.1086 - accuracy: 0.9596 - val_loss: 0.2121 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18393\n",
      "Epoch 13/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.0953 - accuracy: 0.9640 - val_loss: 0.2199 - val_accuracy: 0.9203\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18393\n",
      "Epoch 14/20\n",
      "19200/19200 [==============================] - 79s 4ms/step - loss: 0.0797 - accuracy: 0.9703 - val_loss: 0.2446 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18393\n",
      "Epoch 15/20\n",
      "19200/19200 [==============================] - 81s 4ms/step - loss: 0.0678 - accuracy: 0.9744 - val_loss: 0.2369 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18393\n",
      "Epoch 16/20\n",
      "19200/19200 [==============================] - 82s 4ms/step - loss: 0.0501 - accuracy: 0.9826 - val_loss: 0.2596 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18393\n",
      "Epoch 17/20\n",
      "19200/19200 [==============================] - 82s 4ms/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 0.2746 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.18393\n",
      "Epoch 18/20\n",
      "19200/19200 [==============================] - 78s 4ms/step - loss: 0.0322 - accuracy: 0.9887 - val_loss: 0.2959 - val_accuracy: 0.9203\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18393\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19200/19200 [==============================] - 81s 4ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.3200 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18393\n",
      "Epoch 20/20\n",
      "19200/19200 [==============================] - 81s 4ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.3218 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18393\n",
      "(19200, 30, 300) (19200,) (2133, 30, 300) (2133,)\n",
      "Running Fold 7 / 10\n",
      "Train on 19200 samples, validate on 2133 samples\n",
      "Epoch 1/20\n",
      "19200/19200 [==============================] - 90s 5ms/step - loss: 0.4149 - accuracy: 0.8158 - val_loss: 0.3266 - val_accuracy: 0.8697\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.18393\n",
      "Epoch 2/20\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.3133 - accuracy: 0.8730 - val_loss: 0.2850 - val_accuracy: 0.8847\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18393\n",
      "Epoch 3/20\n",
      "19200/19200 [==============================] - 93s 5ms/step - loss: 0.2696 - accuracy: 0.8920 - val_loss: 0.2951 - val_accuracy: 0.8851\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18393\n",
      "Epoch 4/20\n",
      "19200/19200 [==============================] - 91s 5ms/step - loss: 0.2447 - accuracy: 0.9024 - val_loss: 0.2329 - val_accuracy: 0.9011\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18393\n",
      "Epoch 5/20\n",
      "19200/19200 [==============================] - 94s 5ms/step - loss: 0.2278 - accuracy: 0.9097 - val_loss: 0.2242 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18393\n",
      "Epoch 6/20\n",
      "19200/19200 [==============================] - 95s 5ms/step - loss: 0.2052 - accuracy: 0.9187 - val_loss: 0.2091 - val_accuracy: 0.9180\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18393\n",
      "Epoch 7/20\n",
      "19200/19200 [==============================] - 93s 5ms/step - loss: 0.1932 - accuracy: 0.9265 - val_loss: 0.2167 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18393\n",
      "Epoch 8/20\n",
      "19200/19200 [==============================] - 92s 5ms/step - loss: 0.1757 - accuracy: 0.9314 - val_loss: 0.1980 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18393\n",
      "Epoch 9/20\n",
      "19200/19200 [==============================] - 91s 5ms/step - loss: 0.1566 - accuracy: 0.9401 - val_loss: 0.1914 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18393\n",
      "Epoch 10/20\n",
      "19200/19200 [==============================] - 90s 5ms/step - loss: 0.1403 - accuracy: 0.9480 - val_loss: 0.2071 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18393\n",
      "Epoch 11/20\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.1283 - accuracy: 0.9516 - val_loss: 0.2078 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18393\n",
      "Epoch 12/20\n",
      "19200/19200 [==============================] - 93s 5ms/step - loss: 0.1129 - accuracy: 0.9573 - val_loss: 0.2086 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18393\n",
      "Epoch 13/20\n",
      "19200/19200 [==============================] - 98s 5ms/step - loss: 0.0966 - accuracy: 0.9641 - val_loss: 0.1976 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18393\n",
      "Epoch 14/20\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.0849 - accuracy: 0.9685 - val_loss: 0.2104 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18393\n",
      "Epoch 15/20\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.0690 - accuracy: 0.9764 - val_loss: 0.2242 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18393\n",
      "Epoch 16/20\n",
      "19200/19200 [==============================] - 89s 5ms/step - loss: 0.0574 - accuracy: 0.9799 - val_loss: 0.2399 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18393\n",
      "Epoch 17/20\n",
      "19200/19200 [==============================] - 91s 5ms/step - loss: 0.0467 - accuracy: 0.9834 - val_loss: 0.2411 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.18393\n",
      "Epoch 18/20\n",
      "19200/19200 [==============================] - 93s 5ms/step - loss: 0.0359 - accuracy: 0.9874 - val_loss: 0.2576 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18393\n",
      "Epoch 19/20\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.2707 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18393\n",
      "Epoch 20/20\n",
      "19200/19200 [==============================] - 93s 5ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.2882 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18393\n",
      "(19200, 30, 300) (19200,) (2133, 30, 300) (2133,)\n",
      "Running Fold 8 / 10\n",
      "Train on 19200 samples, validate on 2133 samples\n",
      "Epoch 1/20\n",
      "19200/19200 [==============================] - 95s 5ms/step - loss: 0.4286 - accuracy: 0.8087 - val_loss: 0.2958 - val_accuracy: 0.8880\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.18393\n",
      "Epoch 2/20\n",
      "19200/19200 [==============================] - 92s 5ms/step - loss: 0.3185 - accuracy: 0.8706 - val_loss: 0.2610 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.18393\n",
      "Epoch 3/20\n",
      "19200/19200 [==============================] - 84s 4ms/step - loss: 0.2761 - accuracy: 0.8885 - val_loss: 0.2333 - val_accuracy: 0.9067\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.18393\n",
      "Epoch 4/20\n",
      "19200/19200 [==============================] - 64s 3ms/step - loss: 0.2464 - accuracy: 0.9023 - val_loss: 0.2094 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18393\n",
      "Epoch 5/20\n",
      "19200/19200 [==============================] - 62s 3ms/step - loss: 0.2252 - accuracy: 0.9103 - val_loss: 0.1945 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18393\n",
      "Epoch 6/20\n",
      "19200/19200 [==============================] - 61s 3ms/step - loss: 0.2059 - accuracy: 0.9174 - val_loss: 0.1877 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18393\n",
      "Epoch 7/20\n",
      "19200/19200 [==============================] - 61s 3ms/step - loss: 0.1910 - accuracy: 0.9237 - val_loss: 0.1819 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.18393 to 0.18190, saving model to best_model.h5\n",
      "Epoch 8/20\n",
      "19200/19200 [==============================] - 61s 3ms/step - loss: 0.1722 - accuracy: 0.9321 - val_loss: 0.1777 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18190 to 0.17772, saving model to best_model.h5\n",
      "Epoch 9/20\n",
      "19200/19200 [==============================] - 63s 3ms/step - loss: 0.1586 - accuracy: 0.9402 - val_loss: 0.1709 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.17772 to 0.17087, saving model to best_model.h5\n",
      "Epoch 10/20\n",
      "19200/19200 [==============================] - 61s 3ms/step - loss: 0.1394 - accuracy: 0.9482 - val_loss: 0.1730 - val_accuracy: 0.9348\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17087\n",
      "Epoch 11/20\n",
      "19200/19200 [==============================] - 62s 3ms/step - loss: 0.1250 - accuracy: 0.9530 - val_loss: 0.1663 - val_accuracy: 0.9395\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.17087 to 0.16627, saving model to best_model.h5\n",
      "Epoch 12/20\n",
      "19200/19200 [==============================] - 63s 3ms/step - loss: 0.1103 - accuracy: 0.9572 - val_loss: 0.1889 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16627\n",
      "Epoch 13/20\n",
      "19200/19200 [==============================] - 61s 3ms/step - loss: 0.0950 - accuracy: 0.9661 - val_loss: 0.1767 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16627\n",
      "Epoch 14/20\n",
      "19200/19200 [==============================] - 62s 3ms/step - loss: 0.0818 - accuracy: 0.9685 - val_loss: 0.1855 - val_accuracy: 0.9419\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16627\n",
      "Epoch 15/20\n",
      "19200/19200 [==============================] - 62s 3ms/step - loss: 0.0687 - accuracy: 0.9743 - val_loss: 0.1824 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16627\n",
      "Epoch 16/20\n",
      "19200/19200 [==============================] - 63s 3ms/step - loss: 0.0521 - accuracy: 0.9814 - val_loss: 0.1945 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16627\n",
      "Epoch 17/20\n",
      "19200/19200 [==============================] - 68s 4ms/step - loss: 0.0428 - accuracy: 0.9841 - val_loss: 0.2282 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16627\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19200/19200 [==============================] - 61s 3ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.2360 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16627\n",
      "Epoch 19/20\n",
      "19200/19200 [==============================] - 62s 3ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.2329 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16627\n",
      "Epoch 20/20\n",
      "19200/19200 [==============================] - 65s 3ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.2578 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16627\n",
      "(19200, 30, 300) (19200,) (2133, 30, 300) (2133,)\n",
      "Running Fold 9 / 10\n",
      "Train on 19200 samples, validate on 2133 samples\n",
      "Epoch 1/20\n",
      "19200/19200 [==============================] - 75s 4ms/step - loss: 0.4253 - accuracy: 0.8121 - val_loss: 0.3420 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.16627\n",
      "Epoch 2/20\n",
      "19200/19200 [==============================] - 66s 3ms/step - loss: 0.3127 - accuracy: 0.8726 - val_loss: 0.2920 - val_accuracy: 0.8819\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16627\n",
      "Epoch 3/20\n",
      "19200/19200 [==============================] - 64s 3ms/step - loss: 0.2699 - accuracy: 0.8927 - val_loss: 0.2585 - val_accuracy: 0.8950\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16627\n",
      "Epoch 4/20\n",
      "19200/19200 [==============================] - 67s 4ms/step - loss: 0.2417 - accuracy: 0.9027 - val_loss: 0.2557 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16627\n",
      "Epoch 5/20\n",
      "19200/19200 [==============================] - 68s 4ms/step - loss: 0.2233 - accuracy: 0.9111 - val_loss: 0.2317 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16627\n",
      "Epoch 6/20\n",
      "19200/19200 [==============================] - 66s 3ms/step - loss: 0.2040 - accuracy: 0.9208 - val_loss: 0.2242 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16627\n",
      "Epoch 7/20\n",
      "19200/19200 [==============================] - 70s 4ms/step - loss: 0.1845 - accuracy: 0.9292 - val_loss: 0.2190 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16627\n",
      "Epoch 8/20\n",
      "19200/19200 [==============================] - 66s 3ms/step - loss: 0.1721 - accuracy: 0.9335 - val_loss: 0.2081 - val_accuracy: 0.9180\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16627\n",
      "Epoch 9/20\n",
      "19200/19200 [==============================] - 67s 3ms/step - loss: 0.1567 - accuracy: 0.9406 - val_loss: 0.2032 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16627\n",
      "Epoch 10/20\n",
      "19200/19200 [==============================] - 67s 4ms/step - loss: 0.1412 - accuracy: 0.9458 - val_loss: 0.2024 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16627\n",
      "Epoch 11/20\n",
      "19200/19200 [==============================] - 68s 4ms/step - loss: 0.1265 - accuracy: 0.9514 - val_loss: 0.2086 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16627\n",
      "Epoch 12/20\n",
      "19200/19200 [==============================] - 69s 4ms/step - loss: 0.1116 - accuracy: 0.9582 - val_loss: 0.1952 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16627\n",
      "Epoch 13/20\n",
      "19200/19200 [==============================] - 69s 4ms/step - loss: 0.0977 - accuracy: 0.9618 - val_loss: 0.2068 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16627\n",
      "Epoch 14/20\n",
      "19200/19200 [==============================] - 69s 4ms/step - loss: 0.0807 - accuracy: 0.9702 - val_loss: 0.2452 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16627\n",
      "Epoch 15/20\n",
      "19200/19200 [==============================] - 70s 4ms/step - loss: 0.0708 - accuracy: 0.9735 - val_loss: 0.2308 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16627\n",
      "Epoch 16/20\n",
      "19200/19200 [==============================] - 68s 4ms/step - loss: 0.0638 - accuracy: 0.9770 - val_loss: 0.2397 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16627\n",
      "Epoch 17/20\n",
      "19200/19200 [==============================] - 69s 4ms/step - loss: 0.0471 - accuracy: 0.9832 - val_loss: 0.2641 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16627\n",
      "Epoch 18/20\n",
      "19200/19200 [==============================] - 68s 4ms/step - loss: 0.0382 - accuracy: 0.9867 - val_loss: 0.2768 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16627\n",
      "Epoch 19/20\n",
      "19200/19200 [==============================] - 69s 4ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.3107 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16627\n",
      "Epoch 20/20\n",
      "19200/19200 [==============================] - 69s 4ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.3058 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16627\n",
      "(19200, 30, 300) (19200,) (2133, 30, 300) (2133,)\n",
      "Running Fold 10 / 10\n",
      "Train on 19200 samples, validate on 2133 samples\n",
      "Epoch 1/20\n",
      "19200/19200 [==============================] - 78s 4ms/step - loss: 0.4234 - accuracy: 0.8148 - val_loss: 0.3404 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.16627\n",
      "Epoch 2/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.3204 - accuracy: 0.8705 - val_loss: 0.2780 - val_accuracy: 0.8828\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16627\n",
      "Epoch 3/20\n",
      "19200/19200 [==============================] - 73s 4ms/step - loss: 0.2762 - accuracy: 0.8879 - val_loss: 0.2419 - val_accuracy: 0.8983\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16627\n",
      "Epoch 4/20\n",
      "19200/19200 [==============================] - 74s 4ms/step - loss: 0.2470 - accuracy: 0.9024 - val_loss: 0.2358 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16627\n",
      "Epoch 5/20\n",
      "19200/19200 [==============================] - 76s 4ms/step - loss: 0.2257 - accuracy: 0.9103 - val_loss: 0.2050 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16627\n",
      "Epoch 6/20\n",
      "19200/19200 [==============================] - 76s 4ms/step - loss: 0.2045 - accuracy: 0.9200 - val_loss: 0.2128 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16627\n",
      "Epoch 7/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.1898 - accuracy: 0.9261 - val_loss: 0.1855 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16627\n",
      "Epoch 8/20\n",
      "19200/19200 [==============================] - 76s 4ms/step - loss: 0.1708 - accuracy: 0.9353 - val_loss: 0.1713 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16627\n",
      "Epoch 9/20\n",
      "19200/19200 [==============================] - 78s 4ms/step - loss: 0.1577 - accuracy: 0.9399 - val_loss: 0.1775 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16627\n",
      "Epoch 10/20\n",
      "19200/19200 [==============================] - 73s 4ms/step - loss: 0.1388 - accuracy: 0.9471 - val_loss: 0.1685 - val_accuracy: 0.9353\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16627\n",
      "Epoch 11/20\n",
      "19200/19200 [==============================] - 70s 4ms/step - loss: 0.1228 - accuracy: 0.9536 - val_loss: 0.1854 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16627\n",
      "Epoch 12/20\n",
      "19200/19200 [==============================] - 68s 4ms/step - loss: 0.1040 - accuracy: 0.9612 - val_loss: 0.1759 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16627\n",
      "Epoch 13/20\n",
      "19200/19200 [==============================] - 67s 3ms/step - loss: 0.0888 - accuracy: 0.9685 - val_loss: 0.1805 - val_accuracy: 0.9339\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16627\n",
      "Epoch 14/20\n",
      "19200/19200 [==============================] - 67s 3ms/step - loss: 0.0760 - accuracy: 0.9721 - val_loss: 0.2069 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16627\n",
      "Epoch 15/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.0604 - accuracy: 0.9790 - val_loss: 0.1995 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16627\n",
      "Epoch 16/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.0496 - accuracy: 0.9818 - val_loss: 0.2201 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16627\n",
      "Epoch 17/20\n",
      "19200/19200 [==============================] - 72s 4ms/step - loss: 0.0388 - accuracy: 0.9865 - val_loss: 0.2379 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16627\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19200/19200 [==============================] - 74s 4ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.2261 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16627\n",
      "Epoch 19/20\n",
      "19200/19200 [==============================] - 69s 4ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.2467 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16627\n",
      "Epoch 20/20\n",
      "19200/19200 [==============================] - 71s 4ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.2662 - val_accuracy: 0.9376\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16627\n"
     ]
    }
   ],
   "source": [
    "##cross_validation 10folds\n",
    "\n",
    "n_folds = 10\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train, valid) in enumerate(skf.split(X_train,y_train)):\n",
    "    print(X_train[train].shape,y_train[train].shape,X_train[valid].shape,y_train[valid].shape)\n",
    "    print (\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    model = None # Clearing the NN.\n",
    "    model = creat_model()\n",
    "    hist=fit_model(model, X_train[train], y_train[train], X_train[valid], y_train[valid])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10667/10667 [==============================] - 23s 2ms/step\n",
      "Test score: 0.1946373532881629\n",
      "Test accuracy: 0.9301584362983704\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#sauvegarder les poids du meilleure model pour les utiliser dans le teste\n",
    "hist.load_weights(\"best_model.h5\")\n",
    "\n",
    "##EVALUATION\n",
    "score, acc = hist.evaluate(X_test, y_test,\n",
    "                            batch_size=128)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score: 0.9775914470379724\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_scores = model.predict_proba(X_test)\n",
    "\n",
    "##afficher les résultats de la prediction\n",
    "roc = roc_auc_score(y_test, y_scores)\n",
    "print('ROC score:', roc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9149    0.9484    0.9313      5328\n",
      "         1.0     0.9465    0.9120    0.9289      5339\n",
      "\n",
      "    accuracy                         0.9302     10667\n",
      "   macro avg     0.9307    0.9302    0.9301     10667\n",
      "weighted avg     0.9307    0.9302    0.9301     10667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = classification_report(y_test, y_pred, digits=4)\n",
    "print('Classification Report \\n')\n",
    "print(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      "\n",
      "[[5053  275]\n",
      " [ 470 4869]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix \\n')\n",
    "print (cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
