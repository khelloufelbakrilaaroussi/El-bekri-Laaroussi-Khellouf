{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/ankeshanand/deep-clickbait-detection/blob/master/src/combined_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Dropout, MaxPooling1D, Convolution1D\n",
    "from keras.layers import LSTM, Lambda, merge, Masking, SimpleRNN, GRU\n",
    "from keras.layers import Embedding, TimeDistributed\n",
    "from keras import backend as K\n",
    "import keras.callbacks\n",
    "\n",
    "from utils import clean_tweet, tokenize_tweet\n",
    "from keras.layers import concatenate\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clickbait=pd.read_csv('clickbait_data',sep='\\n',header=None)\n",
    "data_noclickbait=pd.read_csv('non_clickbait_data',sep='\\n',header=None)\n",
    "\n",
    "data_clickbait.insert(1,\"class\",np.ones(15999))\n",
    "data_noclickbait.insert(1,\"class\",np.zeros(16001))\n",
    "\n",
    "data_Final=pd.concat((data_clickbait,data_noclickbait),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Filipino activist arrested for disrupting Mani...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>International Board fixes soccer field size, h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24 Rules For Women On A First Date With A Man</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Political fallout from the sacking of Professo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Which \"Clueless\" Character Are You Based On Yo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  class\n",
       "0  Filipino activist arrested for disrupting Mani...    0.0\n",
       "1  International Board fixes soccer field size, h...    0.0\n",
       "2      24 Rules For Women On A First Date With A Man    1.0\n",
       "3  Political fallout from the sacking of Professo...    0.0\n",
       "4  Which \"Clueless\" Character Are You Based On Yo...    1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Final = data_Final.sample(frac=1).reset_index(drop=True)\n",
    "#data_Final=data_Final.sample(frac=1)\n",
    "data_Final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v', 't', 'á', 'è', 'é', 'r', 'ó', 'ü', 'd', 'h', 'º', 'î', 'ć', '9', 'ś', 'ñ', 'à', '2', 'j', 'w', 'æ', 'č', 'm', 'n', 'í', '3', 'å', 'ū', 'ł', 'ú', '6', 'o', 'ī', 'ä', 'x', 'a', 'l', '4', 'q', 'p', 'ø', ' ', 'i', 'ö', 'k', 'f', '0', 'ß', 'š', '8', 'ę', 'ž', 'ç', 'b', 'c', 's', '1', 'g', '5', 'ã', 'ń', 'e', 'ș', 'y', 'z', '7', 'u'}\n",
      "total chars: 67\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_Final['cleaned_tweet'] = data_Final[0].apply(clean_tweet)\n",
    "data_Final['tokenized_tweet'] =data_Final[0].apply(tokenize_tweet)\n",
    "\n",
    "all_txt = ''\n",
    "for tweet in data_Final['cleaned_tweet'].values:\n",
    "    all_txt += tweet\n",
    "\n",
    "chars = set(all_txt)\n",
    "print(chars)\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v': 0, 't': 1, 'á': 2, 'è': 3, 'é': 4, 'r': 5, 'ó': 6, 'ü': 7, 'd': 8, 'h': 9, 'º': 10, 'î': 11, 'ć': 12, '9': 13, 'ś': 14, 'ñ': 15, 'à': 16, '2': 17, 'j': 18, 'w': 19, 'æ': 20, 'č': 21, 'm': 22, 'n': 23, 'í': 24, '3': 25, 'å': 26, 'ū': 27, 'ł': 28, 'ú': 29, '6': 30, 'o': 31, 'ī': 32, 'ä': 33, 'x': 34, 'a': 35, 'l': 36, '4': 37, 'q': 38, 'p': 39, 'ø': 40, ' ': 41, 'i': 42, 'ö': 43, 'k': 44, 'f': 45, '0': 46, 'ß': 47, 'š': 48, '8': 49, 'ę': 50, 'ž': 51, 'ç': 52, 'b': 53, 'c': 54, 's': 55, '1': 56, 'g': 57, '5': 58, 'ã': 59, 'ń': 60, 'e': 61, 'ș': 62, 'y': 63, 'z': 64, '7': 65, 'u': 66}\n",
      "{0: 'v', 1: 't', 2: 'á', 3: 'è', 4: 'é', 5: 'r', 6: 'ó', 7: 'ü', 8: 'd', 9: 'h', 10: 'º', 11: 'î', 12: 'ć', 13: '9', 14: 'ś', 15: 'ñ', 16: 'à', 17: '2', 18: 'j', 19: 'w', 20: 'æ', 21: 'č', 22: 'm', 23: 'n', 24: 'í', 25: '3', 26: 'å', 27: 'ū', 28: 'ł', 29: 'ú', 30: '6', 31: 'o', 32: 'ī', 33: 'ä', 34: 'x', 35: 'a', 36: 'l', 37: '4', 38: 'q', 39: 'p', 40: 'ø', 41: ' ', 42: 'i', 43: 'ö', 44: 'k', 45: 'f', 46: '0', 47: 'ß', 48: 'š', 49: '8', 50: 'ę', 51: 'ž', 52: 'ç', 53: 'b', 54: 'c', 55: 's', 56: '1', 57: 'g', 58: '5', 59: 'ã', 60: 'ń', 61: 'e', 62: 'ș', 63: 'y', 64: 'z', 65: '7', 66: 'u'}\n",
      "32000\n",
      "21333\n"
     ]
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print(char_indices)\n",
    "print(indices_char)\n",
    "maxlen = 250\n",
    "print(len(data_Final))\n",
    "split_index = int((2 * len(data_Final)) / 3)\n",
    "print(split_index)\n",
    "df_train , df_test = data_Final[:split_index], data_Final[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>class</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21333</td>\n",
       "      <td>Chinese chemical plant explosion threatens wat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chinese chemical plant explosion threatens wat...</td>\n",
       "      <td>[chinese, chemical, plant, explosion, threaten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21334</td>\n",
       "      <td>A Ham Radio Weekend for Talking to the Moon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a ham radio weekend for talking to the moon</td>\n",
       "      <td>[a, ham, radio, weekend, for, talking, to, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21335</td>\n",
       "      <td>Six-year-old Egyptian boy contracts bird flu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>six year old egyptian boy contracts bird flu</td>\n",
       "      <td>[six, year, old, egyptian, boy, contracts, bir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21336</td>\n",
       "      <td>People Are Not Happy With Justin Bieber After ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>people are not happy with justin bieber after ...</td>\n",
       "      <td>[people, are, not, happy, with, justin, bieber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21337</td>\n",
       "      <td>21 Things You Need For Your Baby If You Were I...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21 things you need for your baby if you were i...</td>\n",
       "      <td>[21, things, you, need, for, your, baby, if, y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  class  \\\n",
       "21333  Chinese chemical plant explosion threatens wat...    0.0   \n",
       "21334        A Ham Radio Weekend for Talking to the Moon    0.0   \n",
       "21335       Six-year-old Egyptian boy contracts bird flu    0.0   \n",
       "21336  People Are Not Happy With Justin Bieber After ...    1.0   \n",
       "21337  21 Things You Need For Your Baby If You Were I...    1.0   \n",
       "\n",
       "                                           cleaned_tweet  \\\n",
       "21333  chinese chemical plant explosion threatens wat...   \n",
       "21334        a ham radio weekend for talking to the moon   \n",
       "21335       six year old egyptian boy contracts bird flu   \n",
       "21336  people are not happy with justin bieber after ...   \n",
       "21337  21 things you need for your baby if you were i...   \n",
       "\n",
       "                                         tokenized_tweet  \n",
       "21333  [chinese, chemical, plant, explosion, threaten...  \n",
       "21334  [a, ham, radio, weekend, for, talking, to, the...  \n",
       "21335  [six, year, old, egyptian, boy, contracts, bir...  \n",
       "21336  [people, are, not, happy, with, justin, bieber...  \n",
       "21337  [21, things, you, need, for, your, baby, if, y...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>class</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Filipino activist arrested for disrupting Mani...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>filipino activist arrested for disrupting mani...</td>\n",
       "      <td>[filipino, activist, arrested, for, disrupting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>International Board fixes soccer field size, h...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>international board fixes soccer field size ha...</td>\n",
       "      <td>[international, board, fixes, soccer, field, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24 Rules For Women On A First Date With A Man</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24 rules for women on a first date with a man</td>\n",
       "      <td>[24, rules, for, women, on, a, first, date, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Political fallout from the sacking of Professo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>political fallout from the sacking of professo...</td>\n",
       "      <td>[political, fallout, from, the, sacking, of, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Which \"Clueless\" Character Are You Based On Yo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>which clueless character are you based on your...</td>\n",
       "      <td>[which, clueless, character, are, you, based, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21328</td>\n",
       "      <td>This Apple Picking Test Will Determine Your Tr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>this apple picking test will determine your tr...</td>\n",
       "      <td>[this, apple, picking, test, will, determine, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21329</td>\n",
       "      <td>Contestant seriously injured during live Germa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>contestant seriously injured during live germa...</td>\n",
       "      <td>[contestant, seriously, injured, during, live,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21330</td>\n",
       "      <td>16 Honest Confessions From People Wearing Puri...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16 honest confessions from people wearing puri...</td>\n",
       "      <td>[16, honest, confessions, from, people, wearin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21331</td>\n",
       "      <td>Christmas Vs. Jewish Christmas: Which Will Win</td>\n",
       "      <td>1.0</td>\n",
       "      <td>christmas vs jewish christmas which will win</td>\n",
       "      <td>[christmas, vs, jewish, christmas, which, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21332</td>\n",
       "      <td>US stock markets soar after bailout plan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>us stock markets soar after bailout plan</td>\n",
       "      <td>[us, stock, markets, soar, after, bailout, plan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21333 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  class  \\\n",
       "0      Filipino activist arrested for disrupting Mani...    0.0   \n",
       "1      International Board fixes soccer field size, h...    0.0   \n",
       "2          24 Rules For Women On A First Date With A Man    1.0   \n",
       "3      Political fallout from the sacking of Professo...    0.0   \n",
       "4      Which \"Clueless\" Character Are You Based On Yo...    1.0   \n",
       "...                                                  ...    ...   \n",
       "21328  This Apple Picking Test Will Determine Your Tr...    1.0   \n",
       "21329  Contestant seriously injured during live Germa...    0.0   \n",
       "21330  16 Honest Confessions From People Wearing Puri...    1.0   \n",
       "21331     Christmas Vs. Jewish Christmas: Which Will Win    1.0   \n",
       "21332           US stock markets soar after bailout plan    0.0   \n",
       "\n",
       "                                           cleaned_tweet  \\\n",
       "0      filipino activist arrested for disrupting mani...   \n",
       "1      international board fixes soccer field size ha...   \n",
       "2          24 rules for women on a first date with a man   \n",
       "3      political fallout from the sacking of professo...   \n",
       "4      which clueless character are you based on your...   \n",
       "...                                                  ...   \n",
       "21328  this apple picking test will determine your tr...   \n",
       "21329  contestant seriously injured during live germa...   \n",
       "21330  16 honest confessions from people wearing puri...   \n",
       "21331       christmas vs jewish christmas which will win   \n",
       "21332           us stock markets soar after bailout plan   \n",
       "\n",
       "                                         tokenized_tweet  \n",
       "0      [filipino, activist, arrested, for, disrupting...  \n",
       "1      [international, board, fixes, soccer, field, s...  \n",
       "2      [24, rules, for, women, on, a, first, date, wi...  \n",
       "3      [political, fallout, from, the, sacking, of, p...  \n",
       "4      [which, clueless, character, are, you, based, ...  \n",
       "...                                                  ...  \n",
       "21328  [this, apple, picking, test, will, determine, ...  \n",
       "21329  [contestant, seriously, injured, during, live,...  \n",
       "21330  [16, honest, confessions, from, people, wearin...  \n",
       "21331  [christmas, vs, jewish, christmas, which, will...  \n",
       "21332   [us, stock, markets, soar, after, bailout, plan]  \n",
       "\n",
       "[21333 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample training data with the clickbait class\n",
    "#df_train_clickbait, df_train_no_clickbait = df_train[df_train['clickbait'] == 1], df_train[df_train['clickbait'] == 0]\n",
    "#oversampled_df_train_clickbait = df_train_clickbait.sample(len(df_train_no_clickbait), replace=True, random_state=42)\n",
    "#df_train = pd.concat([oversampled_df_train_clickbait, df_train_no_clickbait])\n",
    "\n",
    "def binarize(x, sz=37):\n",
    "    return tf.to_float(tf.one_hot(x, sz, on_value=1, off_value=0, axis=-1))\n",
    "\n",
    "def create_feature_matrix(docs):\n",
    "    #print(\"docs= \",docs)\n",
    "    X = np.ones((len(docs), maxlen), dtype=np.int64) * -1\n",
    "   # print(\"X= \",X)\n",
    "    for i, doc in enumerate(docs):\n",
    "       # print(i, doc)\n",
    "        for t, char in enumerate(doc):\n",
    "          #  print(t, char)\n",
    "            X[i, t] = char_indices[char]\n",
    "           # print(\"X[i,t]= \",X[i,t])\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21333, 250)\n"
     ]
    }
   ],
   "source": [
    "X_train= create_feature_matrix(df_train['cleaned_tweet'])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1.]\n",
      "[0. 0. 1. ... 1. 1. 0.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = create_feature_matrix(df_train['cleaned_tweet']), create_feature_matrix(df_test['cleaned_tweet'])\n",
    "y_train, y_test = np.array(df_train['class']), np.array(df_test['class'])\n",
    "print(y_train[:20])\n",
    "print(y_train)\n",
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(len(X_train))\n",
    "np.random.shuffle(ids)\n",
    "X_train = X_train[ids]\n",
    "y_train = y_train[ids]\n",
    "#print(X_train)\n",
    "def binarize_outshape(in_shape):\n",
    "    return in_shape[0], in_shape[1], 37\n",
    "\n",
    "filter_length = [5, 3, 3]\n",
    "nb_filter = [196, 196, 300]\n",
    "pool_length = 2\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=196, kernel_size=5, strides=1, padding=\"valid\", kernel_initializer=\"glorot_normal\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  \n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=196, kernel_size=3, strides=1, padding=\"valid\", kernel_initializer=\"glorot_normal\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=300, kernel_size=3, strides=1, padding=\"valid\", kernel_initializer=\"glorot_normal\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3, implementation=2)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(128, return_sequences=False, go_backwards=True, dropout=0.3, recurrent_dropout=0.3, implementation=2)`\n"
     ]
    }
   ],
   "source": [
    "in_sentence = Input(shape=(maxlen,), dtype='int64')\n",
    "# binarize function creates a onehot encoding of each character index\n",
    "embedded = Lambda(binarize, output_shape=binarize_outshape)(in_sentence)\n",
    "# embedded: encodes sentence\n",
    "for i in range(len(nb_filter)):\n",
    "    embedded = Convolution1D(nb_filter=nb_filter[i],\n",
    "                            filter_length=filter_length[i],\n",
    "                            border_mode='valid',\n",
    "                            activation='relu',\n",
    "                            init='glorot_normal',\n",
    "                            subsample_length=1)(embedded)\n",
    "\n",
    "    embedded = Dropout(0.1)(embedded)\n",
    "    embedded = MaxPooling1D(pool_length=pool_length)(embedded)\n",
    "\n",
    "forward_sent = GRU(64, return_sequences=False, dropout_W=0.3, dropout_U=0.3, consume_less='gpu')(embedded)\n",
    "backward_sent = GRU(64, return_sequences=False, dropout_W=0.3, dropout_U=0.3, consume_less='gpu', go_backwards=True)(embedded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#from keras.engine import merge\n",
    "#concatenate([x1, x2], axis=-1)\n",
    "sent_encode = concatenate([forward_sent, backward_sent], axis=-1)\n",
    "sent_encode = Dropout(0.3)(sent_encode)\n",
    "output = Dense(1, activation='sigmoid')(sent_encode)\n",
    "\n",
    "model = Model(input=in_sentence, output=output)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "earlystop_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 19199 samples, validate on 2134 samples\n",
      "Epoch 1/20\n",
      "19199/19199 [==============================] - 128s 7ms/step - loss: 0.5197 - accuracy: 0.7369 - val_loss: 0.3744 - val_accuracy: 0.8416\n",
      "Epoch 2/20\n",
      "19199/19199 [==============================] - 118s 6ms/step - loss: 0.3561 - accuracy: 0.8495 - val_loss: 0.3131 - val_accuracy: 0.8819\n",
      "Epoch 3/20\n",
      "19199/19199 [==============================] - 123s 6ms/step - loss: 0.2619 - accuracy: 0.8940 - val_loss: 0.2675 - val_accuracy: 0.8936\n",
      "Epoch 4/20\n",
      "19199/19199 [==============================] - 126s 7ms/step - loss: 0.2177 - accuracy: 0.9143 - val_loss: 0.3014 - val_accuracy: 0.8669\n",
      "Epoch 5/20\n",
      "19199/19199 [==============================] - 122s 6ms/step - loss: 0.1917 - accuracy: 0.9264 - val_loss: 0.2077 - val_accuracy: 0.9260\n",
      "Epoch 6/20\n",
      "19199/19199 [==============================] - 127s 7ms/step - loss: 0.1828 - accuracy: 0.9283 - val_loss: 0.2112 - val_accuracy: 0.9147\n",
      "Epoch 7/20\n",
      "19199/19199 [==============================] - 118s 6ms/step - loss: 0.1491 - accuracy: 0.9423 - val_loss: 0.2615 - val_accuracy: 0.8861\n",
      "Epoch 8/20\n",
      "19199/19199 [==============================] - 113s 6ms/step - loss: 0.1319 - accuracy: 0.9484 - val_loss: 0.2195 - val_accuracy: 0.9072\n",
      "Epoch 9/20\n",
      "19199/19199 [==============================] - 113s 6ms/step - loss: 0.1123 - accuracy: 0.9552 - val_loss: 0.2241 - val_accuracy: 0.9072\n",
      "Epoch 10/20\n",
      "19199/19199 [==============================] - 113s 6ms/step - loss: 0.1008 - accuracy: 0.9629 - val_loss: 0.2007 - val_accuracy: 0.9171\n",
      "Epoch 11/20\n",
      "19199/19199 [==============================] - 114s 6ms/step - loss: 0.0801 - accuracy: 0.9704 - val_loss: 0.1981 - val_accuracy: 0.9222\n",
      "Epoch 12/20\n",
      "19199/19199 [==============================] - 115s 6ms/step - loss: 0.0740 - accuracy: 0.9710 - val_loss: 0.2138 - val_accuracy: 0.9250\n",
      "Epoch 13/20\n",
      "19199/19199 [==============================] - 114s 6ms/step - loss: 0.0632 - accuracy: 0.9779 - val_loss: 0.2141 - val_accuracy: 0.9269\n",
      "Epoch 14/20\n",
      "19199/19199 [==============================] - 113s 6ms/step - loss: 0.0617 - accuracy: 0.9766 - val_loss: 0.2153 - val_accuracy: 0.9255\n",
      "Epoch 15/20\n",
      "19199/19199 [==============================] - 114s 6ms/step - loss: 0.0571 - accuracy: 0.9791 - val_loss: 0.2319 - val_accuracy: 0.9236\n",
      "Epoch 16/20\n",
      "19199/19199 [==============================] - 114s 6ms/step - loss: 0.0457 - accuracy: 0.9828 - val_loss: 0.2508 - val_accuracy: 0.9269\n",
      "Epoch 17/20\n",
      "19199/19199 [==============================] - 114s 6ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.2375 - val_accuracy: 0.9194\n",
      "Epoch 18/20\n",
      "19199/19199 [==============================] - 114s 6ms/step - loss: 0.0512 - accuracy: 0.9816 - val_loss: 0.2278 - val_accuracy: 0.9269\n",
      "Epoch 00018: early stopping\n",
      "10667/10667 [==============================] - 14s 1ms/step\n",
      "Test score: 0.23806049367771764\n",
      "Test accuracy: 0.9245336055755615\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=20, validation_split=0.1, callbacks=[earlystop_cb])\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.1048737e-05]\n",
      " [4.2374343e-02]\n",
      " [3.5193563e-04]\n",
      " ...\n",
      " [9.9982435e-01]\n",
      " [9.9999988e-01]\n",
      " [6.5911445e-04]]\n"
     ]
    }
   ],
   "source": [
    "def predict_classes(model, X_test):\n",
    "    proba = model.predict(X_test)\n",
    "    print(proba)\n",
    "    if proba.shape[-1] > 1:\n",
    "        return proba.argmax(axis=-1)\n",
    "    else:\n",
    "        return (proba > 0.5).astype('int32')\n",
    "\n",
    "y_pred = predict_classes(model, X_test)\n",
    "y_scores = model.predict(X_test)\n",
    "#print(y_pred)\n",
    "#print(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score: 0.9766658229361119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "roc = roc_auc_score(y_test, y_scores)\n",
    "print('ROC score:', roc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8992    0.9573    0.9274      5367\n",
      "         1.0     0.9538    0.8913    0.9215      5300\n",
      "\n",
      "    accuracy                         0.9245     10667\n",
      "   macro avg     0.9265    0.9243    0.9244     10667\n",
      "weighted avg     0.9263    0.9245    0.9244     10667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = classification_report(y_test, y_pred, digits=4)\n",
    "print('Classification Report \\n')\n",
    "print (metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      "\n",
      "[[5138  229]\n",
      " [ 576 4724]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix \\n')\n",
    "print (cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
